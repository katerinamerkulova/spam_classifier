{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация текстов: спам-фильтр для SMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы взяли открытый датасет с SMS-сообщениями, размеченными на спам (\"spam\") и не спам (\"ham\"), построили на нем классификатор текстов на эти два класса, оценили его качество с помощью кросс-валидации, протестировали его работу на отдельных примерах, и посмотрели, что будет происходить с качеством, если менять параметры модели.\n",
    "\n",
    "1. Загрузили датасет. Описание датасета можно посмотреть здесь: https://www.kaggle.com/uciml/sms-spam-collection-dataset.\n",
    "\n",
    "2. Считайли датасет в Python, выяснили, что используется в качестве разделителей и как проставляются метки классов.\n",
    "\n",
    "3. Подготовили для дальнейшей работы два списка: список текстов и список соответствующих им меток классов. В качестве метки класса использовали 1 для спама и 0 для \"не спама\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер выборки: 5573\n",
      "Количество не спама: 4826\n",
      "Количество спама: 747\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file = open('SMSSpamCollection.txt', \"r\", encoding=\"utf-8\").read()\n",
    "ham = re.findall('ham\\t(.+)\\n', file)\n",
    "spam = re.findall('spam\\t(.+)\\n', file)\n",
    "\n",
    "data = ham + spam\n",
    "labels = [0]*len(ham) + [1]*len(spam)\n",
    "\n",
    "print('Размер выборки:', len(data))\n",
    "print('Количество не спама:', len(ham))\n",
    "print('Количество спама:', len(spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Используя sklearn.feature_extraction.text.CountVectorizer со стандартными настройками, получили из текстов матрицу признаков X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Сделали классификацию текстов с помощью LogisticRegression() с параметрами по умолчанию и оценили качество sklearn.cross_validation.cross_val_score и посчитав среднее арифметическое качества на отдельных fold'ах. Установили random_state=2. Параметр cv равее 10. В качестве метрики качества использовали f1-меру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9311269283144492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "random_state = 2\n",
    "logreg = LogisticRegression(solver='lbfgs')\n",
    "print(cross_val_score(logreg, X, labels, scoring='f1', cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Далее обучили классификатор на всей выборке и спрогнозируйте с его помощью класс для следующих сообщений:\n",
    "\n",
    "\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\"\n",
    "\n",
    "\"FreeMsg: Txt: claim your reward of 3 hours talk time\"\n",
    "\n",
    "\"Have you visited the last lecture on physics?\"\n",
    "\n",
    "\"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\"\n",
    "\n",
    "\"Only 99$\"\n",
    "\n",
    "Прогнозы классификатора (0 - не спам, 1 - спам), записанные через пробел, будут ответом в одном из вопросов ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf_pipeline = Pipeline(\n",
    "            [(\"vectorizer\", vectorizer), (\"classifier\", logreg)])\n",
    "\n",
    "clf_pipeline.fit(data, labels)\n",
    "\n",
    "test = [\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\",\n",
    "        \"FreeMsg: Txt: claim your reward of 3 hours talk time\",\n",
    "        \"Have you visited the last lecture on physics?\",\n",
    "        \"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\",\n",
    "        \"Only 99$\"]\n",
    "\n",
    "print(clf_pipeline.predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Задали в CountVectorizer параметр ngram_range=(2,2), затем ngram_range=(3,3), затем ngram_range=(1,3). Во всех трех случаях измерили получившееся в кросс-валидации значение f1-меры. В данном эксперименте мы пробовали добавлять в признаки n-граммы для разных диапазонов n - только биграммы, только триграммы, и, наконец, все вместе - униграммы, биграммы и триграммы. Обратим внимание, что статистики по биграммам и триграммам намного меньше, поэтому классификатор только на них работает хуже. В то же время это не ухудшает результат сколько-нибудь существенно, если добавлять их вместе с униграммами, т.к. за счет регуляризации линейный классификатор не склонен сильно переобучаться на этих признаках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2) 0.816782323945987\n",
      "(3, 3) 0.7250161555467377\n",
      "(1, 3) 0.922300452240204\n"
     ]
    }
   ],
   "source": [
    "for var in [(2, 2), (3, 3), (1, 3)]:\n",
    "    vectorizer = CountVectorizer(ngram_range=var)\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    random_state = 2\n",
    "    score = cross_val_score(logreg, X, labels, scoring='f1', cv=10).mean()\n",
    "    print(var, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Повторили аналогичный п.7 эксперимент, используя вместо логистической регрессии MultinomialNB(). Обратим внимание, насколько сильнее (по сравнению с линейным классификатором) наивный Байес страдает от нехватки статистики по биграммам и триграммам.\n",
    "\n",
    "По какой-то причине обучение наивного байесовского классификатора через Pipeline происходит с ошибкой. Чтобы получить правильный ответ, мы отдельно посчитали частоты слов и обучили классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2) 0.6454554013558982\n",
      "(3, 3) 0.37862343087618666\n",
      "(1, 3) 0.8879054608894993\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "for var in [(2, 2), (3, 3), (1, 3)]:\n",
    "    vectorizer = CountVectorizer(ngram_range=var)\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    random_state = 2\n",
    "    score = cross_val_score(nb, X, labels, scoring='f1', cv=10).mean()\n",
    "    print(var, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Попробовали использовать в логистической регрессии в качестве признаков Tf*idf из TfidfVectorizer на униграммах.\n",
    "Качество на кросс-валидации понизилось по сравнению с CountVectorizer на униграммах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "0.8511210908899957\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "0.9311269283144492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "for vectorizer in [TfidfVectorizer(ngram_range=(1, 1)), CountVectorizer(ngram_range=(1, 1))]:\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    random_state = 2\n",
    "    score = cross_val_score(logreg, X, labels, scoring='f1', cv=10).mean()\n",
    "    print(vectorizer)\n",
    "    print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
